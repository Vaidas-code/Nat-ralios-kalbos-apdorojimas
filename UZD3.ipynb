{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\"> Uždavinių atlikimui naudokite tekstą esantį dokumente `tekstas1.txt`. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Atspausdinkite antro sakinio kalbos vienetus, Pos žymas, smulkiagretes POS žymas ir jų aprašymą (angl. token text, the POS tag, the fine-grained TAG tag, and the description of the fine-grained tag). Uždavinį atlikite su spaCy biblioteka "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One      NUM   CD  cardinal number\n",
      "day      NOUN  NN  noun, singular or mass\n",
      "the      DET   DT  determiner\n",
      "donkey   NOUN  NN  noun, singular or mass\n",
      "suddenly ADV   RB  adverb\n",
      "tumbled  VERB  VBD verb, past tense\n",
      "down     ADP   IN  conjunction, subordinating or preposition\n",
      "the      DET   DT  determiner\n",
      "stream   NOUN  NN  noun, singular or mass\n",
      "and      CCONJ CC  conjunction, coordinating\n",
      "the      DET   DT  determiner\n",
      "salt     NOUN  NN  noun, singular or mass\n",
      "bag      NOUN  NN  noun, singular or mass\n",
      "also     ADV   RB  adverb\n",
      "fell     VERB  VBD verb, past tense\n",
      "into     ADP   IN  conjunction, subordinating or preposition\n",
      "the      DET   DT  determiner\n",
      "water    NOUN  NN  noun, singular or mass\n",
      ".        PUNCT .   punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "with open('tekstas.txt', 'r', encoding='utf-8') as failas:\n",
    "    tekstas = failas.read()\n",
    "doc = nlp(tekstas)\n",
    "sakiniai = list(doc.sents)\n",
    "antras_sakinys = sakiniai[2]\n",
    "for token in antras_sakinys:\n",
    "    print(f'{token.text:{8}} {token.pos_:{5}} {token.tag_:{3}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pateikite dokumento POS žymų dažnumo sąrašą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84. ADJ   : 10\n",
      " 85. ADP   : 9\n",
      " 86. ADV   : 9\n",
      " 87. AUX   : 5\n",
      " 89. CCONJ : 6\n",
      " 90. DET   : 32\n",
      " 92. NOUN  : 39\n",
      " 93. NUM   : 1\n",
      " 94. PART  : 8\n",
      " 95. PRON  : 7\n",
      " 96. PROPN : 1\n",
      " 97. PUNCT : 13\n",
      " 98. SCONJ : 1\n",
      " 100. VERB  : 24\n",
      " 103. SPACE : 7\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "with open('tekstas.txt', 'r', encoding='utf-8') as file:\n",
    "    tekstas = file.read()\n",
    "doc = nlp(tekstas)\n",
    "POS_kiekis = Counter([token.pos for token in doc])\n",
    "for k, v in sorted(POS_kiekis.items()):\n",
    "    print(f' {k}. {doc.vocab[k].text:{6}}: {v}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Atspausdinkite visus tekste esančius būdvardžius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Foolish', 'light', 'happy', 'same', 'next', 'same', 'lighter', 'dampened', 'heavy', 'happy']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "with open('tekstas.txt', 'r', encoding='utf-8') as file:\n",
    "    tekstas = file.read()\n",
    "\n",
    "doc = nlp(tekstas)\n",
    "\n",
    "budvardziai = [token.text for token in doc if token.pos_ == 'ADJ']\n",
    "\n",
    "print(budvardziai)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Atspausdinkite visus tekste esančius prielinksnius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['on', 'to', 'On', 'down', 'into', 'in', 'to', 'on', 'after']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "with open('tekstas.txt', 'r', encoding='utf-8') as file:\n",
    "    tekstas = file.read()\n",
    "\n",
    "doc = nlp(tekstas)\n",
    "\n",
    "budvardziai = [token.text for token in doc if token.pos_ == 'ADP']\n",
    "print(budvardziai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Koks procentas tokenų yra veiksmažodžiai?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.95\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "with open('tekstas.txt', 'r', encoding='utf-8') as file:\n",
    "    tekstas = file.read()\n",
    "\n",
    "doc = nlp(tekstas)\n",
    "\n",
    "visi_zodziai = len(doc)\n",
    "veiksmazodziai = sum(1 for token in doc if token.pos_ == 'VERB')\n",
    "\n",
    "veiksmazodziu_procentai = (veiksmazodziai / visi_zodziai) * 100\n",
    "\n",
    "print(f'{veiksmazodziu_procentai:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Atspausdinkite 2-ro sakinio tokenus ir POS žymas. Uždavinį atlikite su NLTK biblioteka "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color= blue> https://www.nltk.org/book/ch05.html </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('One', 'CD'), ('day', 'NN'), ('the', 'DT'), ('donkey', 'NN'), ('suddenly', 'RB'), ('tumbled', 'VBD'), ('down', 'RP'), ('the', 'DT'), ('stream', 'NN'), ('and', 'CC'), ('the', 'DT'), ('salt', 'NN'), ('bag', 'NN'), ('also', 'RB'), ('fell', 'VBD'), ('into', 'IN'), ('the', 'DT'), ('water', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Vaidas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "with open('tekstas.txt', 'r', encoding='utf-8') as file:\n",
    "    tekstas = file.read()\n",
    "\n",
    "sakiniai = nltk.sent_tokenize(tekstas)\n",
    "antras_sakinys = sentences[2]\n",
    "\n",
    "zodziai = nltk.word_tokenize(antras_sakinys)\n",
    "\n",
    "pos_tagai = nltk.pos_tag(zodziai)\n",
    "\n",
    "print(pos_tagai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Iš turimo teksto (t.y. viso nuskaityto teksto) pašalinkite visus veiksmažodžius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Foolish Donkey \n",
      " A salt seller to the salt bag on his donkey to the market every day . \n",
      " On the way they to a stream . One day the donkey suddenly down the stream and the salt bag also into the water . The salt in the water and hence the bag very light to . The donkey was happy . \n",
      " Then the donkey to the same trick every day . \n",
      " The salt seller to the trick and to a lesson to it . The next day he a cotton bag on the donkey . \n",
      " Again it the same trick that the cotton bag would be still lighter . \n",
      " But the dampened cotton very heavy to and the donkey . It a lesson . It did not the trick anymore after that day , and the seller was happy . \n",
      " "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "with open('tekstas.txt', 'r', encoding='utf-8') as file:\n",
    "    tekstas = file.read()\n",
    "\n",
    "doc = nlp(tekstas)\n",
    "\n",
    "veiksmazodziai = {token.text for token in doc if token.pos_ == 'VERB'}\n",
    "\n",
    "for token in doc:\n",
    "    if token.text not in veiksmazodziai:\n",
    "        print(token.text, end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
